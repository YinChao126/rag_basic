import os
import json
import requests
from openai import OpenAI

def chat_qwen(prompt, model, stream=False):
    client = OpenAI(
        api_key=os.environ.get('QWEN_API_KEY'),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )
    print("----- qwen request start -----")

    completion = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant"},
            {"role": "user", "content": prompt},
        ],
        stream=stream,
        temperature=0.1,
        # top_p=0.9,
    )

    try:
        if stream:
            def generate_content():
                for chunk in completion:
                    if chunk.choices[0].delta.content is not None:
                        yield chunk.choices[0].delta.content
            return generate_content()
        else:
            return completion.choices[0].message.content
    except Exception as e:
        print(e)
        return "fail to response"

if __name__ == '__main__':
    import os
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.environ.get("QWEN_API_KEY"):
        print("âŒ é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ QWEN_API_KEY")
        exit(1)
    
    query = "å…¬å¸æŠ¥é”€æµç¨‹æ˜¯æ€æ ·çš„ï¼Ÿ"
    print(f"\n{'='*60}")
    print(f"â“ é—®é¢˜: {query}")
    print(f"{'='*60}\n")
    
    print("ğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”ï¼ˆçº¯LLMï¼Œæ— çŸ¥è¯†åº“ï¼‰...")
    answer = chat_qwen(query, "qwen3-max")
    
    print(f"\n{'='*60}")
    print("â¡ï¸  å›ç­”:")
    print(f"{'='*60}")
    print(answer)
    print(f"{'='*60}")