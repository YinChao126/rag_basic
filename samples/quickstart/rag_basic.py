# rag_basic_qwen_simple.py
"""
æç®€ RAG ç¤ºä¾‹ï¼ˆæ¼”ç¤ºï¼šåˆ‡ç‰‡ -> å‘é‡åŒ– -> å­˜å‚¨ -> å¬å› -> æ‹¼ä¸Šä¸‹æ–‡ -> è°ƒç”¨ QWENï¼‰

æœ¬ç¤ºä¾‹å±•ç¤ºäº†RAGç³»ç»Ÿçš„æ ¸å¿ƒæµç¨‹ï¼š
1. æ–‡æ¡£è¯»å–ä¸åˆ‡ç‰‡
2. å‘é‡åŒ–ä¸å­˜å‚¨
3. æ£€ç´¢ä¸ç”Ÿæˆ
"""

import os
import sys
from glob import glob
from openai import OpenAI
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.vectorstores import Chroma

# -----------------------
# é…ç½®åŒº
# -----------------------
DATA_DIR = "data"               # æ”¾ç½® .md/.txt çŸ¥è¯†æ–‡ä»¶çš„ç›®å½•
PERSIST_DIR = "chroma_db"       # chroma æŒä¹…åŒ–ç›®å½•
CHUNK_SIZE = 500                # åˆ‡ç‰‡å¤§å°ï¼ˆå­—ç¬¦ï¼‰
CHUNK_OVERLAP = 100             # åˆ‡ç‰‡é‡å ï¼ˆå­—ç¬¦ï¼‰
TOP_K = 3                       # æ£€ç´¢ top-k å€¼
QWEN_MODEL = "qwen3-max"        # qwen æ¨¡å‹åï¼ŒæŒ‰å®é™…æ›¿æ¢

# -----------------------
# 1) è¯»å–æ‰€æœ‰æ–‡æ¡£
# -----------------------
try:
    file_paths = glob(os.path.join(DATA_DIR, "*.md")) + glob(os.path.join(DATA_DIR, "*.txt"))
    if not file_paths:
        raise FileNotFoundError(f"è¯·åœ¨ {DATA_DIR}/ ç›®å½•æ”¾å…¥ç¤ºä¾‹ .md æˆ– .txt æ–‡ä»¶ï¼ˆUTF-8 ç¼–ç ï¼‰")
except Exception as e:
    print(f"âŒ é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡æ¡£ç›®å½• - {e}")
    sys.exit(1)

raw_docs = []
for p in file_paths:
    try:
        # ä½¿ç”¨ UTF-8 ç¼–ç è¯»å–æ–‡ä»¶ï¼Œè‹¥æ–‡ä»¶ä¸æ˜¯ UTF-8 è¯·å…ˆè½¬ç 
        with open(p, "r", encoding="utf-8") as f:
            text = f.read()
        if not text.strip():
            print(f"âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ {p} ä¸ºç©ºï¼Œå·²è·³è¿‡")
            continue
        raw_docs.append({"text": text, "source": os.path.basename(p)})
    except UnicodeDecodeError:
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ {p} ç¼–ç ä¸æ˜¯ UTF-8ï¼Œè¯·å…ˆè½¬æ¢ç¼–ç ")
        sys.exit(1)
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Šï¼šè¯»å–æ–‡ä»¶ {p} æ—¶å‡ºé”™ - {e}ï¼Œå·²è·³è¿‡")
        continue

if not raw_docs:
    print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡æ¡£")
    sys.exit(1)

# -----------------------
# 2) ç®€å•åˆ‡ç‰‡
# -----------------------
chunks = []      # å­˜å‚¨æ‰€æœ‰æ–‡æœ¬ç‰‡æ®µï¼ˆå­—ç¬¦ä¸²ï¼‰
metadatas = []   # ä¸ chunks å¯¹åº”çš„å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æ¥æºæ–‡ä»¶åã€ç‰‡æ®µåºå·ï¼‰

for doc in raw_docs:
    txt = doc["text"]
    start = 0
    idx = 0
    while start < len(txt):
        end = min(start + CHUNK_SIZE, len(txt))  # ç¡®ä¿ä¸è¶Šç•Œ
        chunk_text = txt[start:end].strip()  # å»é™¤é¦–å°¾ç©ºç™½
        
        # è·³è¿‡ç©ºç‰‡æ®µ
        if not chunk_text:
            break
            
        # è®°å½•æ¥æºå’Œç‰‡æ®µç´¢å¼•ï¼Œä¾¿äºè¿½æº¯
        meta = {"source": doc["source"], "chunk_index": idx}
        chunks.append(chunk_text)
        metadatas.append(meta)
        idx += 1
        
        # ä¸‹ä¸€ä¸ªç‰‡æ®µèµ·å§‹ä½ç½®ï¼ˆåŒ…å«é‡å ï¼Œé¿å…é‡å¤ï¼‰
        start = end - CHUNK_OVERLAP if end - CHUNK_OVERLAP > start else end
        if start >= len(txt):  # é˜²æ­¢æ— é™å¾ªç¯
            break

print(f"âœ… å·²è¯»å– {len(raw_docs)} ä¸ªæ–‡æ¡£ï¼Œåˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µã€‚")

# -----------------------
# 3) Embedding -> å†™å…¥ Chromaï¼ˆå‘é‡åŒ–å¹¶å­˜å‚¨ï¼‰
# -----------------------
def build_or_load_vectorstore(chunks, metadatas, persist_dir, embedding_model):
    """
    æ„å»ºæˆ–åŠ è½½å‘é‡æ•°æ®åº“
    
    å¦‚æœæ•°æ®åº“ä¸å­˜åœ¨æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œåˆ™é‡æ–°æ„å»º
    å¦‚æœæ•°æ®åº“å­˜åœ¨ä¸”å®Œæ•´ï¼Œåˆ™ç›´æ¥åŠ è½½
    """
    import shutil
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.environ.get("QWEN_API_KEY"):
        raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ QWEN_API_KEY")
    
    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
    db_exists = os.path.exists(persist_dir) and os.path.isdir(persist_dir)
    
    if db_exists:
        try:
            # å°è¯•åŠ è½½å·²æœ‰æ•°æ®åº“
            print(f"ğŸ“‚ æ£€æµ‹åˆ°å·²æœ‰å‘é‡æ•°æ®åº“ï¼Œæ­£åœ¨åŠ è½½...")
            vect = Chroma(
                persist_directory=persist_dir,
                embedding_function=embedding_model
            )
            # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦æœ‰æ•°æ®
            if vect._collection.count() > 0:
                print(f"âœ… æˆåŠŸåŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“ï¼ˆåŒ…å« {vect._collection.count()} æ¡è®°å½•ï¼‰")
                return vect
            else:
                print("âš ï¸  æ•°æ®åº“ä¸ºç©ºï¼Œå°†é‡æ–°æ„å»º...")
                # åˆ é™¤ç©ºæ•°æ®åº“
                shutil.rmtree(persist_dir)
        except Exception as e:
            print(f"âš ï¸  åŠ è½½æ•°æ®åº“å¤±è´¥: {e}ï¼Œå°†é‡æ–°æ„å»º...")
            # åˆ é™¤æŸåçš„æ•°æ®åº“
            if os.path.exists(persist_dir):
                shutil.rmtree(persist_dir)
    
    # æ„å»ºæ–°æ•°æ®åº“
    print(f"ğŸ”¨ æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“...")
    print(f"   - æ–‡æ¡£æ•°é‡: {len(chunks)}")
    print(f"   - åˆ‡ç‰‡å¤§å°: {CHUNK_SIZE} å­—ç¬¦")
    print(f"   - é‡å å¤§å°: {CHUNK_OVERLAP} å­—ç¬¦")
    
    vect = Chroma.from_texts(
        texts=chunks, 
        embedding=embedding_model, 
        metadatas=metadatas, 
        persist_directory=persist_dir
    )
    
    # æŒä¹…åŒ–å‘é‡æ•°æ®åº“
    try:
        vect.persist()
        print(f"âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆå¹¶å·²ä¿å­˜åˆ° {persist_dir}")
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Šï¼šå‘é‡æ•°æ®åº“æŒä¹…åŒ–å¤±è´¥ - {e}")
    
    return vect

try:
    # åˆå§‹åŒ– Embedding æ¨¡å‹
    emb = DashScopeEmbeddings(model="text-embedding-v4")
    print("âœ… Embedding æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    
    # æ„å»ºæˆ–åŠ è½½å‘é‡æ•°æ®åº“
    # æ³¨æ„ï¼šå¦‚æœæ•°æ®åº“å·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œä¼šç›´æ¥åŠ è½½ï¼›å¦åˆ™ä¼šé‡æ–°æ„å»º
    vect = build_or_load_vectorstore(chunks, metadatas, PERSIST_DIR, emb)

except ValueError as e:
    print(f"âŒ é…ç½®é”™è¯¯ï¼š{e}")
    print("ğŸ’¡ æç¤ºï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ QWEN_API_KEY")
    print("   Windows: set QWEN_API_KEY=your_key")
    print("   Linux/Mac: export QWEN_API_KEY=your_key")
    sys.exit(1)
except Exception as e:
    print(f"âŒ é”™è¯¯ï¼šå‘é‡åŒ–å¤±è´¥ - {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# -----------------------
# 4) ç®€å•æ£€ç´¢ï¼šä½¿ç”¨ vect.as_retriever å¹¶æ£€ç´¢ top-k æ–‡æ¡£
# -----------------------
try:
    retriever = vect.as_retriever(search_kwargs={"k": TOP_K})
    print(f"âœ… æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆtop_k={TOP_K}ï¼‰")
except Exception as e:
    print(f"âŒ é”™è¯¯ï¼šæ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥ - {e}")
    sys.exit(1)

# -----------------------
# 5) LLMè°ƒç”¨
# -----------------------
# æ­¤å¤„å¤ç”¨ only_llm.py çš„å®ç°
try:
    from only_llm import chat_qwen
except ImportError:
    print("âŒ é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ only_llm æ¨¡å—ï¼Œè¯·ç¡®ä¿ only_llm.py æ–‡ä»¶å­˜åœ¨")
    sys.exit(1)

# -----------------------
# 6) æŠŠæ£€ç´¢åˆ°çš„ç‰‡æ®µæ‹¼æˆ prompt
# -----------------------
def build_prompt(query, docs):
    """
    æ„å»º RAG æç¤ºè¯
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
    
    Returns:
        æ„å»ºå¥½çš„æç¤ºè¯å­—ç¬¦ä¸²
    """
    if not docs:
        return f"ç”¨æˆ·é—®é¢˜ï¼š{query}\n\næ³¨æ„ï¼šæœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ï¼Œè¯·å›ç­”\"æˆ‘ä¸çŸ¥é“\"ã€‚"
    
    parts = []
    for i, d in enumerate(docs, start=1):
        # å…¼å®¹ä¸åŒè¿”å›ç»“æ„ï¼ˆDocumentå¯¹è±¡æˆ–å­—å…¸ï¼‰
        text = getattr(d, "page_content", str(d))
        src = d.metadata.get("source", "unknown") if hasattr(d, "metadata") else "unknown"
        parts.append(f"[ç‰‡æ®µ {i} | æ¥æº: {src}]\n{text}\n")
    
    context = "\n".join(parts)
    prompt = (
        "ä¸‹é¢æ˜¯æ£€ç´¢åˆ°çš„çŸ¥è¯†ç‰‡æ®µï¼ˆå¯èƒ½æœ‰å†—ä½™ï¼‰ï¼Œè¯· **åªåŸºäºè¿™äº›ç‰‡æ®µ** å›ç­”é—®é¢˜ã€‚\n"
        "å¦‚æœç‰‡æ®µä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·å›ç­”\"æˆ‘ä¸çŸ¥é“\"ã€‚\n\n"
        f"å·²æ£€ç´¢åˆ°çš„ç‰‡æ®µï¼š\n{context}\n\n"
        f"ç”¨æˆ·é—®é¢˜ï¼š{query}\n\n"
        "è¯·ç»™å‡ºç®€æ´å‡†ç¡®çš„å›ç­”ï¼Œå¹¶åœ¨æœ€ååˆ—å‡ºå¼•ç”¨æ¥æºï¼ˆæ–‡ä»¶åå’Œç‰‡æ®µç¼–å·ï¼‰ã€‚"
    )
    return prompt

# -----------------------
# 7) RAGæŸ¥è¯¢å‡½æ•°ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰
# -----------------------
def rag_query(query, retriever_instance=None, model=QWEN_MODEL):
    """
    RAGæŸ¥è¯¢å‡½æ•°
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        retriever_instance: æ£€ç´¢å™¨å®ä¾‹ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨å…¨å±€retrieverï¼‰
        model: LLMæ¨¡å‹åç§°
    
    Returns:
        dict: åŒ…å«answerå’Œsourcesçš„å­—å…¸
    """
    if retriever_instance is None:
        retriever_instance = retriever
    
    try:
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = retriever_instance.invoke(query)
        
        if not docs:
            return {
                "answer": "æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•å›ç­”ã€‚",
                "sources": []
            }
        
        # æ„å»ºæç¤ºè¯
        prompt = build_prompt(query, docs)
        
        # è°ƒç”¨ LLM ç”Ÿæˆå›ç­”
        answer = chat_qwen(prompt, model=model, stream=False)
        
        # æå–æ¥æº
        sources = []
        for i, d in enumerate(docs, start=1):
            src = d.metadata.get("source", "unknown") if hasattr(d, "metadata") else "unknown"
            sources.append(f"{src} ç‰‡æ®µ {i}")
        
        return {
            "answer": answer,
            "sources": sources
        }
    except Exception as e:
        return {
            "answer": f"æŸ¥è¯¢å¤±è´¥: {e}",
            "sources": []
        }

# -----------------------
# 8) è¿è¡Œç¤ºä¾‹æŸ¥è¯¢
# -----------------------
if __name__ == "__main__":
    query = "å…¬å¸æŠ¥é”€æµç¨‹æ˜¯æ€æ ·çš„ï¼Ÿ"
    print(f"\n{'='*60}")
    print(f"â“ é—®é¢˜: {query}")
    print(f"{'='*60}\n")
    
    try:
        result = rag_query(query)
        
        # è¾“å‡ºç»“æœ
        print(f"\n{'='*60}")
        print("â¡ï¸  RAGå›ç­”:")
        print(f"{'='*60}")
        print(result["answer"])
        
        # è¾“å‡ºå¼•ç”¨æ¥æº
        if result["sources"]:
            print(f"\n{'='*60}")
            print("ğŸ“š å¼•ç”¨æ¥æº:")
            print(f"{'='*60}")
            for src in result["sources"]:
                print(f"- {src}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šæŸ¥è¯¢å¤±è´¥ - {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)