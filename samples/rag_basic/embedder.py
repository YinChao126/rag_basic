import os
import json
from openai import OpenAI
from langchain_community.embeddings import OllamaEmbeddings
from pathlib import Path

# å¸¸é‡å®šä¹‰
EMBED_MODEL = "text-embedding-v4"
DEFAULT_TOP_RERANK = 10

def embed_text(texts: any, model: str = EMBED_MODEL):
    """
    å°†å•ä¸ªå­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨è½¬ä¸ºå‘é‡ã€‚
    è¿”å›ï¼šå¦‚æœè¾“å…¥æ˜¯å­—ç¬¦ä¸²ï¼Œè¿”å› list(float)ï¼›å¦‚æœè¾“å…¥æ˜¯ list[str]ï¼Œè¿”å› list[list[float]]
    ä½¿ç”¨ Aliyun-compatible OpenAI SDK (OpenAI class) to call embeddings.create.
    """
    client = OpenAI(api_key=os.environ.get("QWEN_API_KEY"),
                    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    single_input = False
    if isinstance(texts, str):
        texts = [texts]
        single_input = True

    # æ£€æŸ¥æ‰¹é‡å¤§å°ï¼Œå¦‚æœè¶…è¿‡10ä¸ªåˆ™åˆ†æ‰¹å¤„ç†
    if len(texts) > DEFAULT_TOP_RERANK:
        embeddings = []
        for i in range(0, len(texts), DEFAULT_TOP_RERANK):
            batch = texts[i:i+DEFAULT_TOP_RERANK]
            res = client.embeddings.create(model=model, input=batch)
            embeddings.extend([item.embedding for item in res.data])
    else:
        # è°ƒç”¨ embeddings API
        res = client.embeddings.create(model=model, input=texts)
        embeddings = [item.embedding for item in res.data]

    return embeddings[0] if single_input else embeddings

def main():
    import os
    from pathlib import Path
    from datetime import datetime
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.environ.get("QWEN_API_KEY"):
        print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ QWEN_API_KEY")
        exit(1)
    
    # é…ç½®å‚æ•°
    chunks_file = output_dir / "chunks.json"
    if not chunks_file.exists():
        chunks_file = Path("chunks.json")
    
    if not chunks_file.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°åˆ‡ç‰‡æ–‡ä»¶ {chunks_file}")
        print("ğŸ’¡ æç¤ºï¼šè¯·å…ˆè¿è¡Œ chunker.py ç”Ÿæˆåˆ‡ç‰‡æ–‡ä»¶")
        exit(1)
    
    print("=" * 70)
    print("ğŸ”¢ æ–‡æœ¬å‘é‡åŒ–æµ‹è¯•")
    print("=" * 70)
    
    # åŠ è½½åˆ‡ç‰‡
    print(f"\nğŸ“– æ­£åœ¨åŠ è½½åˆ‡ç‰‡æ–‡ä»¶...")
    print(f"   æ–‡ä»¶è·¯å¾„: {chunks_file}")
    
    with open(chunks_file, "r", encoding="utf-8") as f:
        chunks = json.load(f)
    
    texts = [c["text"] for c in chunks]
    ids = [c["id"] for c in chunks]
    
    print(f"âœ… åŠ è½½æˆåŠŸ")
    print(f"   - åˆ‡ç‰‡æ•°é‡: {len(texts)} ä¸ª")
    print(f"   - å¹³å‡é•¿åº¦: {sum(len(t) for t in texts) / len(texts):.0f} å­—ç¬¦")
    
    # ========== ä½¿ç”¨é˜¿é‡Œäº‘æ¨¡å‹ ==========
    print(f"\n{'='*70}")
    print("æ–¹æ³•1ï¼šä½¿ç”¨é˜¿é‡Œäº‘ text-embedding-v4 æ¨¡å‹")
    print(f"{'='*70}")
    
    batch_size = 10
    print(f"ğŸ“ å¼€å§‹å‘é‡åŒ–...")
    print(f"   - æ¨¡å‹: {EMBED_MODEL}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   - é¢„è®¡æ‰¹æ¬¡: {(len(texts) + batch_size - 1) // batch_size} æ‰¹")
    
    start_time = datetime.now()
    vectors = embed_text(texts, model=EMBED_MODEL)
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    if len(vectors) != len(texts):
        raise RuntimeError("embeddings æ•°é‡ä¸æ–‡æœ¬æ•°é‡ä¸ä¸€è‡´")
    
    print(f"âœ… å‘é‡åŒ–å®Œæˆï¼")
    print(f"   - è€—æ—¶: {duration:.2f} ç§’")
    print(f"   - å‘é‡ç»´åº¦: {len(vectors[0])} ç»´")
    print(f"   - å¤„ç†é€Ÿåº¦: {len(texts)/duration:.1f} ä¸ª/ç§’")
    
    # ä¿å­˜ç»“æœ
    output_file = output_dir / "embeddings.jsonl"
    with open(output_file, "w", encoding="utf-8") as fout:
        for i, vec in enumerate(vectors):
            item = {
                "id": ids[i],
                "source": chunks[i]["source"],
                "embedding_len": len(vec),
                "text_preview": texts[i][:120].replace("\n", " "),
                "embedding": vec
            }
            fout.write(json.dumps(item, ensure_ascii=False) + "\n")
    
    print(f"   - è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # ========== ä½¿ç”¨Ollamaæ¨¡å‹ï¼ˆå¯é€‰ï¼‰==========
    print(f"\n{'='*70}")
    print("æ–¹æ³•2ï¼šä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹ï¼ˆå¯é€‰å¯¹æ¯”ï¼‰")
    print(f"{'='*70}")
    
    try:
        print(f"ğŸ“ å°è¯•è¿æ¥æœ¬åœ°OllamaæœåŠ¡...")
        emb_ollama = OllamaEmbeddings(model="all-minilm:latest")
        
        print(f"âœ… è¿æ¥æˆåŠŸ")
        print(f"   - æ¨¡å‹: all-minilm:latest")
        
        start_time = datetime.now()
        vectors_ollama = emb_ollama.embed_documents(texts)
        end_time = datetime.now()
        duration_ollama = (end_time - start_time).total_seconds()
        
        if len(vectors_ollama) != len(texts):
            raise RuntimeError("embeddings æ•°é‡ä¸æ–‡æœ¬æ•°é‡ä¸ä¸€è‡´")
        
        print(f"âœ… å‘é‡åŒ–å®Œæˆï¼")
        print(f"   - è€—æ—¶: {duration_ollama:.2f} ç§’")
        print(f"   - å‘é‡ç»´åº¦: {len(vectors_ollama[0])} ç»´")
        print(f"   - å¤„ç†é€Ÿåº¦: {len(texts)/duration_ollama:.1f} ä¸ª/ç§’")
        
        # ä¿å­˜ç»“æœ
        output_file_ollama = output_dir / "embeddings_ollama.jsonl"
        with open(output_file_ollama, "w", encoding="utf-8") as fout:
            for i, vec in enumerate(vectors_ollama):
                item = {
                    "id": ids[i],
                    "source": chunks[i]["source"],
                    "embedding_len": len(vec),
                    "text_preview": texts[i][:120].replace("\n", " "),
                    "embedding": vec
                }
                fout.write(json.dumps(item, ensure_ascii=False) + "\n")
        
        print(f"   - è¾“å‡ºæ–‡ä»¶: {output_file_ollama}")
        
        # å¯¹æ¯”æ€»ç»“
        print(f"\n{'='*70}")
        print("ğŸ“Š å‘é‡åŒ–æ¨¡å‹å¯¹æ¯”")
        print(f"{'='*70}")
        print(f"{'æ¨¡å‹':<30} {'ç»´åº¦':<15} {'è€—æ—¶':<15} {'é€Ÿåº¦':<15}")
        print("-" * 70)
        print(f"{'text-embedding-v4 (äº‘ç«¯)':<30} {len(vectors[0]):<15} {duration:.2f}ç§’{'':<10} {len(texts)/duration:.1f}ä¸ª/ç§’")
        print(f"{'all-minilm:latest (æœ¬åœ°)':<30} {len(vectors_ollama[0]):<15} {duration_ollama:.2f}ç§’{'':<10} {len(texts)/duration_ollama:.1f}ä¸ª/ç§’")
        print(f"{'='*70}")
        
    except Exception as e:
        print(f"âš ï¸  æœ¬åœ°Ollamaæ¨¡å‹ä¸å¯ç”¨: {e}")
        print("ğŸ’¡ æç¤ºï¼šå¯ä»¥è·³è¿‡æ­¤æ­¥éª¤ï¼Œä½¿ç”¨äº‘ç«¯æ¨¡å‹å³å¯")
    
    print(f"\nâœ… å‘é‡åŒ–æµç¨‹å®Œæˆï¼")
    print(f"ğŸ’¡ æç¤ºï¼šå‘é‡åŒ–åçš„æ•°æ®å°†ç”¨äºæ„å»ºå‘é‡æ•°æ®åº“")

if __name__ == "__main__":
    main()



