# llm_with_rag.py
"""
æç®€ RAG æŸ¥è¯¢è„šæœ¬ï¼š
  - åŠ è½½ chroma_db
  - å¯¹ user query åšæ£€ç´¢ï¼ˆtop_kï¼‰
  - æŠŠæ£€ç´¢åˆ°çš„ç‰‡æ®µæ‹¼æˆ prompt
  - é€šè¿‡ OpenAI-compatible client (ä½ æä¾›çš„ qwen æ¥å£) è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›ç­”
ç”¨æ³•ï¼š
  export QWEN_API_KEY="..."
  python llm_with_rag.py --persist_dir chroma_db --k 3
"""

import os
import argparse
import logging
from openai import OpenAI   # ç”¨ä½ ä¹‹å‰çš„ only_llm é£æ ¼æ¥å…¥ qwen (openai-compatible)
from langchain_community.vectorstores import Chroma

# æ·»åŠ QwenEmbeddingså¯¼å…¥
from store_manager import QwenEmbeddings

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def make_prompt(query: str, docs):
    parts = []
    for i, d in enumerate(docs, start=1):
        text = getattr(d, "page_content", getattr(d, "content", str(d)))
        src = d.metadata.get("source", "unknown") if hasattr(d, "metadata") else "unknown"
        parts.append(f"[ç‰‡æ®µ {i} | æ¥æº: {src}]\n{text}\n")
    context = "\n".join(parts)
    prompt = (
        "ä¸‹é¢æ˜¯æ£€ç´¢åˆ°çš„çŸ¥è¯†ç‰‡æ®µï¼ˆä»…ä¾›å‚è€ƒï¼‰ã€‚è¯·**ä»…åŸºäºè¿™äº›ç‰‡æ®µ**å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œ"
        "å¦‚æœç‰‡æ®µä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·å›ç­”â€œæˆ‘ä¸çŸ¥é“â€ã€‚\n\n"
        f"{context}\nç”¨æˆ·é—®é¢˜ï¼š{query}\n\nè¯·ç»™å‡ºç®€æ´å‡†ç¡®çš„å›ç­”ï¼Œå¹¶åœ¨æœ«å°¾åˆ—å‡ºå¼•ç”¨æ¥æºã€‚"
    )
    return prompt

def qwen_chat(prompt, model="qwen3-max", temperature=0.1):
    client = OpenAI(api_key=os.environ.get("QWEN_API_KEY"),
                    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    completion = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant that must only answer based on provided context."},
            {"role": "user", "content": prompt},
        ],
        temperature=temperature,
        max_tokens=512,
    )
    return completion.choices[0].message.content

def main():
    import os
    from pathlib import Path
    from datetime import datetime
    
    parser = argparse.ArgumentParser(description="RAGé—®ç­”æµ‹è¯•")
    parser.add_argument("--persist_dir", "-p", default="chroma_db", help="å‘é‡æ•°æ®åº“è·¯å¾„")
    parser.add_argument("--k", type=int, default=3, help="æ£€ç´¢top-kæ•°é‡")
    parser.add_argument("--query", "-q", default="å¦‚ä½•æ›´æ¢ç”µæ± ?", help="æŸ¥è¯¢é—®é¢˜")
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.environ.get("QWEN_API_KEY"):
        print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ QWEN_API_KEY")
        exit(1)
    
    print("=" * 70)
    print("ğŸ” RAGé—®ç­”æµ‹è¯•")
    print("=" * 70)
    
    # æ£€æŸ¥å‘é‡æ•°æ®åº“
    if not os.path.exists(args.persist_dir):
        print(f"âŒ é”™è¯¯ï¼šå‘é‡æ•°æ®åº“ä¸å­˜åœ¨: {args.persist_dir}")
        print("ğŸ’¡ æç¤ºï¼šè¯·å…ˆè¿è¡Œ store_manager.py æ„å»ºå‘é‡æ•°æ®åº“")
        exit(1)
    
    # åŠ è½½å‘é‡æ•°æ®åº“
    print(f"\nğŸ“‚ æ­£åœ¨åŠ è½½å‘é‡æ•°æ®åº“...")
    print(f"   æ•°æ®åº“è·¯å¾„: {args.persist_dir}")
    
    emb = QwenEmbeddings()
    vect = Chroma(persist_directory=args.persist_dir, embedding_function=emb)
    retriever = vect.as_retriever(search_kwargs={"k": args.k})
    
    # è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
    try:
        count = vect._collection.count() if hasattr(vect, '_collection') else "æœªçŸ¥"
        print(f"âœ… åŠ è½½æˆåŠŸ")
        print(f"   - å‘é‡æ•°é‡: {count}")
        print(f"   - æ£€ç´¢top-k: {args.k}")
    except:
        print(f"âœ… åŠ è½½æˆåŠŸ")
    
    # æ‰§è¡Œæ£€ç´¢
    query = args.query
    print(f"\nâ“ ç”¨æˆ·é—®é¢˜: {query}")
    print(f"\nğŸ” æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
    
    start_time = datetime.now()
    docs = retriever.invoke(query)
    retrieval_time = (datetime.now() - start_time).total_seconds()
    
    print(f"âœ… æ£€ç´¢å®Œæˆï¼")
    print(f"   - æ£€ç´¢è€—æ—¶: {retrieval_time:.3f} ç§’")
    print(f"   - æ£€ç´¢åˆ°ç‰‡æ®µ: {len(docs)} ä¸ª")
    
    if not docs:
        print("âš ï¸  è­¦å‘Šï¼šæœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£")
        exit(1)
    
    # æ˜¾ç¤ºæ£€ç´¢åˆ°çš„ç‰‡æ®µ
    print(f"\nğŸ“„ æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µ:")
    print("-" * 70)
    for i, d in enumerate(docs, start=1):
        content = getattr(d, "page_content", getattr(d, "content", str(d)))
        src = d.metadata.get("source", "unknown") if hasattr(d, "metadata") else "unknown"
        print(f"\nç‰‡æ®µ {i} (æ¥æº: {src}):")
        print(f"  {content[:150]}..." if len(content) > 150 else f"  {content}")
    print("-" * 70)
    
    # æ„å»ºPrompt
    print(f"\nğŸ“ æ­£åœ¨æ„å»ºPrompt...")
    prompt = make_prompt(query, docs)
    print(f"âœ… Promptæ„å»ºå®Œæˆ")
    print(f"   - Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(f"\nğŸ“‹ Prompté¢„è§ˆï¼ˆå‰300å­—ç¬¦ï¼‰:")
    print("-" * 70)
    print(prompt[:300] + "..." if len(prompt) > 300 else prompt)
    print("-" * 70)
    
    # è°ƒç”¨LLMç”Ÿæˆå›ç­”
    print(f"\nğŸ¤– æ­£åœ¨è°ƒç”¨LLMç”Ÿæˆå›ç­”...")
    print(f"   - æ¨¡å‹: qwen3-max")
    print(f"   - Temperature: 0.1 (ä½æ¸©åº¦ï¼Œä¿è¯å‡†ç¡®æ€§)")
    
    start_time = datetime.now()
    answer = qwen_chat(prompt, model="qwen3-max", temperature=0.1)
    generation_time = (datetime.now() - start_time).total_seconds()
    
    print(f"âœ… å›ç­”ç”Ÿæˆå®Œæˆï¼")
    print(f"   - ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
    
    # è¾“å‡ºç»“æœ
    print(f"\n{'='*70}")
    print("â¡ï¸  RAGå›ç­”:")
    print(f"{'='*70}")
    print(answer)
    print(f"{'='*70}")
    
    # è¾“å‡ºå¼•ç”¨æ¥æº
    print(f"\nğŸ“š å¼•ç”¨æ¥æº:")
    print("-" * 70)
    sources_info = []
    for i, d in enumerate(docs, start=1):
        content = getattr(d, "page_content", getattr(d, "content", str(d)))
        src = d.metadata.get("source", "unknown") if hasattr(d, "metadata") else "unknown"
        print(f"{i}. {src}")
        print(f"   é¢„è§ˆ: {content[:80]}...")
        sources_info.append({"index": i, "source": src, "content": content[:100]})
    
    # ä¿å­˜ç»“æœ
    output_file = output_dir / "rag_answer.txt"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("=" * 70 + "\n")
        f.write("RAGé—®ç­”ç»“æœ\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"é—®é¢˜: {query}\n\n")
        f.write("å›ç­”:\n")
        f.write(answer)
        f.write("\n\n")
        f.write("å¼•ç”¨æ¥æº:\n")
        for info in sources_info:
            f.write(f"{info['index']}. {info['source']}\n")
            f.write(f"   {info['content']}...\n")
        f.write("\n")
        f.write("=" * 70 + "\n")
        f.write(f"æ£€ç´¢è€—æ—¶: {retrieval_time:.3f} ç§’\n")
        f.write(f"ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’\n")
        f.write(f"æ€»è€—æ—¶: {retrieval_time + generation_time:.2f} ç§’\n")
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"\nğŸ’¡ æç¤ºï¼š")
    print(f"   - æ£€ç´¢è€—æ—¶: {retrieval_time:.3f} ç§’")
    print(f"   - ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
    print(f"   - æ€»è€—æ—¶: {retrieval_time + generation_time:.2f} ç§’")

if __name__ == "__main__":
    main()