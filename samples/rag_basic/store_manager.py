"""
æŠŠ chunks.json å†™å…¥ Chroma å‘é‡æ•°æ®åº“ã€‚
ç”¨æ³•ï¼š
  python store_manager.py --chunks chunks.json --persist_dir chroma_db
è¯´æ˜ï¼š
  - æœ¬ç¤ºä¾‹ç”¨ Chroma.from_texts (è‡ªåŠ¨è°ƒç”¨ embeddings) æ¥æ„å»ºå‘é‡åº“ï¼Œç®€å•æ˜“æ‡‚ã€‚
  - å¦‚æœ chroma_db ç›®å½•å­˜åœ¨ï¼Œä¼šè¦†ç›–/æ›´æ–°ï¼ˆå–å†³äº chroma ç‰ˆæœ¬ï¼‰ã€‚
"""

import os
import json
from openai import OpenAI
from langchain_community.vectorstores import Chroma
from pathlib import Path

# å¸¸é‡å®šä¹‰
EMBED_MODEL = "text-embedding-v4"
DEFAULT_TOP_RERANK = 10

class QwenEmbeddings:
    """é˜¿é‡Œäº‘åƒé—®åµŒå…¥æ¨¡å‹åŒ…è£…ç±»"""
    def __init__(self):
        self.client = OpenAI(
            api_key=os.environ.get("QWEN_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )

    def embed_documents(self, texts):
        """å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡ŒåµŒå…¥"""
        # æ£€æŸ¥æ‰¹é‡å¤§å°ï¼Œå¦‚æœè¶…è¿‡10ä¸ªåˆ™åˆ†æ‰¹å¤„ç†
        if len(texts) > DEFAULT_TOP_RERANK:
            embeddings = []
            for i in range(0, len(texts), DEFAULT_TOP_RERANK):
                batch = texts[i:i+DEFAULT_TOP_RERANK]
                res = self.client.embeddings.create(model=EMBED_MODEL, input=batch)
                embeddings.extend([item.embedding for item in res.data])
        else:
            # è°ƒç”¨ embeddings API
            res = self.client.embeddings.create(model=EMBED_MODEL, input=texts)
            embeddings = [item.embedding for item in res.data]
        
        return embeddings

    def embed_query(self, text):
        """å¯¹å•ä¸ªæŸ¥è¯¢è¿›è¡ŒåµŒå…¥"""
        res = self.client.embeddings.create(model=EMBED_MODEL, input=[text])
        return res.data[0].embedding

def main():
    import os
    import shutil
    from pathlib import Path
    from datetime import datetime
    
    # é…ç½®å‚æ•°
    chunks_file = Path("output/chunks.json")
    if not chunks_file.exists():
        chunks_file = Path("chunks.json")
    
    persist_dir = "chroma_db"
    
    print("=" * 70)
    print("ğŸ’¾ å‘é‡æ•°æ®åº“æ„å»º")
    print("=" * 70)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.environ.get("QWEN_API_KEY"):
        print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ QWEN_API_KEY")
        exit(1)
    
    # æ£€æŸ¥åˆ‡ç‰‡æ–‡ä»¶
    if not chunks_file.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°åˆ‡ç‰‡æ–‡ä»¶ {chunks_file}")
        print("ğŸ’¡ æç¤ºï¼šè¯·å…ˆè¿è¡Œ chunker.py ç”Ÿæˆåˆ‡ç‰‡æ–‡ä»¶")
        exit(1)
    
    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(persist_dir):
        print(f"\nâš ï¸  æ£€æµ‹åˆ°å·²æœ‰å‘é‡æ•°æ®åº“: {persist_dir}")
        response = input("   æ˜¯å¦åˆ é™¤å¹¶é‡å»ºï¼Ÿ(y/n): ").strip().lower()
        if response == 'y':
            shutil.rmtree(persist_dir)
            print(f"   âœ… å·²åˆ é™¤æ—§æ•°æ®åº“")
        else:
            print(f"   âš ï¸  ä¿ç•™æ—§æ•°æ®åº“ï¼Œå°†æ›´æ–°æ•°æ®")
    
    # åŠ è½½åˆ‡ç‰‡
    print(f"\nğŸ“– æ­£åœ¨åŠ è½½åˆ‡ç‰‡æ–‡ä»¶...")
    print(f"   æ–‡ä»¶è·¯å¾„: {chunks_file}")
    
    with open(chunks_file, "r", encoding="utf-8") as f:
        chunks = json.load(f)
    
    texts = [c["text"] for c in chunks]
    metadatas = [{"id": c["id"], "source": c["source"]} for c in chunks]
    
    print(f"âœ… åŠ è½½æˆåŠŸ")
    print(f"   - åˆ‡ç‰‡æ•°é‡: {len(texts)} ä¸ª")
    
    # æ„å»ºå‘é‡æ•°æ®åº“
    print(f"\nğŸ”¨ æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“...")
    print(f"   - Embeddingæ¨¡å‹: text-embedding-v4")
    print(f"   - æ•°æ®åº“è·¯å¾„: {persist_dir}")
    print(f"   - å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...")
    
    start_time = datetime.now()
    emb = QwenEmbeddings()
    vect = Chroma.from_texts(
        texts=texts, 
        embedding=emb, 
        metadatas=metadatas, 
        persist_directory=persist_dir
    )
    
    # æŒä¹…åŒ–
    try:
        vect.persist()
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼")
        print(f"   - è€—æ—¶: {duration:.2f} ç§’")
        print(f"   - å­˜å‚¨è·¯å¾„: {persist_dir}")
        print(f"   - å‘é‡æ•°é‡: {vect._collection.count() if hasattr(vect, '_collection') else len(texts)}")
        
    except Exception as e:
        print(f"âš ï¸  æŒä¹…åŒ–è­¦å‘Š: {e}")
        print(f"   æ•°æ®åº“å·²æ„å»ºï¼Œä½†æŒä¹…åŒ–å¯èƒ½å¤±è´¥")
    
    print(f"\nğŸ’¡ æç¤ºï¼š")
    print(f"   - å‘é‡æ•°æ®åº“å·²ä¿å­˜ï¼Œå¯ä»¥ç”¨äºæ£€ç´¢")
    print(f"   - è¿è¡Œ llm_with_rag.py è¿›è¡ŒRAGé—®ç­”æµ‹è¯•")

if __name__ == "__main__":
    main()



